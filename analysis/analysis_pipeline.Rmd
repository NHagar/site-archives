---
title: "Analysis pipeline"
author: "Nick Hagar, Jack Bandy"
date: "11/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(zoo)
library(jsonlite)
```

##Load in data
```{r}
df <- read_csv('../pacific-standard/ps-archive-patched.csv')
df2 <- read_csv('../thinkprogress/full-info-thinkprogress.csv')
df3 <- read_csv('../splinter/splinter-archive-patched.csv')
df4 <- read_csv('../DNAinfo/DNA-info-chicago-info.csv')
df5 <- read_csv('../DNAinfo/DNA-info-new-york-info.csv')

g_one <- fromJSON("../gawker/gawker-archive.json")
g_two <- fromJSON("../gawker/gawker-archive_pickups.json")
df6 <- rbind(g_one, g_two)
```
##Combine data - bind rows
``` {r}
#Iron out dataframe specifics
df <- df %>% select(-X1, -`Unnamed: 0`) %>% mutate(pub='Pacific Standard')
df2 <- df2 %>% select(-pub_date) %>% rename("pub_date"=datetime, "byline_updated"=byline) %>% mutate(pub='Think Progress')
df3 <- df3 %>% select(-X1, -pageviews) %>% 
  mutate(pub='Splinter', pub_date=as.POSIXct(pub_date, format = "%m/%d/%y %I:%M %p")) %>% 
  rename("byline_updated"=byline)
df4 <- df4 %>% mutate(pub='DNAinfo-Chicago', pub_date=as.POSIXct(pub_date, format="%B %d, %Y %I:%M%p")) %>% rename('byline_updated'=byline)
df5 <- df5 %>% mutate(pub='DNAinfo-NY', pub_date=as.POSIXct(pub_date, format="%B %d, %Y %I:%M%p")) %>% rename('byline_updated'=byline)
df6 <- df6 %>% mutate(pub='Gawker', pub_date=as.POSIXct(pub_date, format="%m/%d/%y %I:%M %p")) %>% rename('byline_updated'=byline)


d <- bind_rows(df, df2, df3, df4, df5, df6)
```

##Set up time aggregation columns, remove duplicates
```{r}
d <- d %>% 
  mutate(monthyear=as.yearmon(pub_date), weekyear=paste(week(pub_date), year(pub_date), sep=' '))

d <- d %>% unique()
```
##Transform raw data to measures
It would be cool to do this all in one block. Not sure if my R skills are up for that though. 

Measures we decided on:
* Story count
* Bylines
* Sections
* Tags (active)
* Stories per byline
* Byline duration
* Story length - classification
* In/out link ratio
* Image credits
* Quotes/excerpts
* Story rate per day
* Clickbait in headlines
```{r}
ldf <- d %>% 
  select(-html_body) %>%
  group_by(pub) %>% 
  mutate(words=log(str_count(text_body, ' ')), words_classification=ntile(words, 3)) %>% 
  filter(!is.na(words_classification)) %>% 
  select(-text_body) %>% 
  spread(key=words_classification, value=words_classification, fill=0) %>% 
  group_by(pub, monthyear) %>% 
  summarize(count_short=sum(ifelse(`1`>0,1,0)),
            count_med=sum(ifelse(`2`>0,1,0)),
            count_long=sum(ifelse(`3`>0,1,0)))


tdf <- d %>% 
  separate(sections, into=c('s1','s2','s3', 's4'), sep=';') %>% 
  gather(`s1`:`s4`, key='hierarchy', value='section') %>% 
  separate(tags, into=c('t1','t2','t3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13', 't14', 't15', 't16', 't17', 't18', 't19', 't20', 't21', 't22', 't23', 't24', 't25'), sep=';') %>% 
  gather(`t1`:`t25`, key='thierarchy', value='tag') %>% 
  group_by(pub, monthyear) %>% 
  summarize(sections=n_distinct(section),
            tags=n_distinct(tag))


adf <- d %>% 
  group_by(pub, monthyear) %>% 
  summarize(story_count=n(),
            byline=n_distinct(byline_updated),
            storiesper=story_count/byline)

agg_stats <- left_join(left_join(adf, ldf), tdf) %>% filter(!is.na(monthyear) & monthyear>1980)


agg_stats
```

##Figure town
``` {r}
agg_stats %>%
  arrange(monthyear) %>% 
  mutate(norm_count=story_count/max(story_count), norm_days=row_number()/max(row_number())) %>% 
  ggplot(aes(norm_days, norm_count, color=pub)) + 
  geom_smooth(method='auto')

agg_stats %>%
  arrange(monthyear) %>% 
  mutate(norm_byline=byline/max(byline), norm_days=row_number()/max(row_number())) %>% 
  ggplot(aes(norm_days, norm_byline, color=pub)) + 
  geom_smooth(method='auto')
```

##NOTES
* Disambiguate sections and tags across publications